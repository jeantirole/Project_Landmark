
## Overview 
### (1) Topic: 
- 웹크롤링을 통해서 수집한 랜드마크 이미지를 사용해 CNN 분류 모델을 
  학습시키고 성능을 개선 시키는 방안들을 탐구 

### (2) Dataset:
- 랜드마크 카테고리 : 17개 
- 크롤링 이미지 수 : 6800장 
- 불필요 이미지 제거 후 : 4,426장 

- 01 :"Eiffel Tower"
- 02 :"Cristo Redentor"
- 03 :"Triumphal Arch"
- 04 :"Wànlĭ Chángchéng"
- 05 :"Taj Mahal"
- 06 :"Sungnyemun Gate"
- 07 :"Moai"
- 08 :"Seokguram buddha"
- 09 :"Golden Gate"
- 10 :"Statue of Liberty"
- 11 :"Torre di Pisa"
- 12 :"Colosseum"
- 13 :"Santiago Bernabéu"
- 14 :"Sphinx"
- 15 :"Burj Khalifa"
- 16 :"London Eye"
- 17 :"London Tower Bridge" 

### (3) Model Performance Improvement: 
- Keras Sequential Model 
- Hyper Parameter Set 
- Layer options (Convolution2D, Activation, MaxPooling, Dropout, etc.) 
- Other options (image augmentation, VGG-16, Evaluation criteria : top3 acc) 


## I. Dataset build 
- 데이터 경로 확인 및 지정 
- 이미지 카테고리 리스트 생성 
- Train & Test 데이터로 스플릿 
- Numpy 형태로 이미지 데이터 저장

## II. Model build
- 데이터 로딩 함수 생성 
- 모델 구성 함수 생성(Convolution2D, Activation, MaxPooling, Dropout, etc.) 
- 모델 학습 함수 생성(batch_size, epochs)  
- 모델 평가 함수 생성(loss & accuracy) 

## III. Model run
- 테스트 이미지 목록 
- 테스트 이미지를 활용한 예측 모델 실행 
- 결과 출력 





```python
from sklearn import model_selection
from sklearn.model_selection import train_test_split
from PIL import Image

import os, glob
import numpy as np
```

## I. Dataset build 


```python
# 데이터 경로 확인 및 지정 
print(os.getcwd())
```

    E:\Python_2019_Eric
    


```python
root_dir = './landmark/'
```


```python
# 이미지 카테고리 리스트 생성 
categories = [
"Eiffel Tower"
,"Cristo Redentor"
,"Triumphal Arch"
,"Wànlĭ Chángchéng"
,"Taj Mahal"
,"Sungnyemun Gate"
,"Moai"
,"Seokguram buddha"
,"Golden Gate"
,"Statue of Liberty"
,"Torre di Pisa"
,"Colosseum"
,"Santiago Bernabéu"
,"Sphinx"
,"Burj Khalifa"
,"London Eye"
,"London Tower Bridge" 
] 
```


```python
# 이미지 정보 
nb_classes = len(categories)
image_width = 64
image_height = 64
```


```python
# 데이터 변수
X = []   # 이미지 데이터
Y = []   # 레이블 데이터
```


```python
# 이미지 데이터 로드 및 배열형태로 전환 
for idx, category in enumerate(categories):   # enumerate : 인덱스, 값 반환
    image_dir = root_dir + category
    files = glob.glob(image_dir + '/' + '*.jpg')   # glob : 지정한 경로에 있는 파일 리스트를 가져옴
    print(image_dir + '/' + '*.jpg')
    print('해당 폴더 파일 갯수 : ',len(files))   # 이미지를 제대로 불러왔는지 확인
    
    for i, f in enumerate(files):   # 이미지 로딩
        img = Image.open(f)         # 01 이미지 파일 불러오기
        img = img.convert('RGB')    # 02 RGB로 변환
        img = img.resize((image_width, image_height))  # 03 이미지 크기를 resize
        data = np.asarray(img)      # 04 해당 이미지를 숫자 배열 데이터로 변경
        X.append(data)              # 05 변경한 데이터를 X의 리스트에 추가
        Y.append(idx)               # 06 해당 idx(이미지가 속한 범주)에 추가(Y값)

X = np.array(X)
Y = np.array(Y)

```

    ./landmark/Eiffel Tower/*.jpg
    해당 폴더 파일 갯수 :  296
    ./landmark/Cristo Redentor/*.jpg
    해당 폴더 파일 갯수 :  314
    ./landmark/Triumphal Arch/*.jpg
    해당 폴더 파일 갯수 :  70
    ./landmark/Wànlĭ Chángchéng/*.jpg
    해당 폴더 파일 갯수 :  182
    ./landmark/Taj Mahal/*.jpg
    해당 폴더 파일 갯수 :  131
    ./landmark/Sungnyemun Gate/*.jpg
    해당 폴더 파일 갯수 :  227
    ./landmark/Moai/*.jpg
    해당 폴더 파일 갯수 :  281
    ./landmark/Seokguram buddha/*.jpg
    해당 폴더 파일 갯수 :  184
    ./landmark/Golden Gate/*.jpg
    해당 폴더 파일 갯수 :  288
    ./landmark/Statue of Liberty/*.jpg
    해당 폴더 파일 갯수 :  279
    ./landmark/Torre di Pisa/*.jpg
    해당 폴더 파일 갯수 :  260
    ./landmark/Colosseum/*.jpg
    해당 폴더 파일 갯수 :  331
    ./landmark/Santiago Bernabéu/*.jpg
    해당 폴더 파일 갯수 :  362
    ./landmark/Sphinx/*.jpg
    해당 폴더 파일 갯수 :  301
    ./landmark/Burj Khalifa/*.jpg
    해당 폴더 파일 갯수 :  309
    ./landmark/London Eye/*.jpg
    해당 폴더 파일 갯수 :  330
    ./landmark/London Tower Bridge/*.jpg
    해당 폴더 파일 갯수 :  281
    


```python
print(X.shape)
print(Y.shape)
```

    (4426, 64, 64, 3)
    (4426,)
    


```python
# Train & Test 데이터로 스플릿 (default: 0.75 : 0.25)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y)
xy = (X_train, X_test, Y_train, Y_test)
```


```python
# Numpy 형태로 이미지 데이터 저장
np.save(root_dir + 'landmark.npy', xy)
```


```python
import sys, os
from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.utils import np_utils
import numpy as np
```

    Using TensorFlow backend.
    

## II. Model build


```python
# 데이터 로딩 함수 생성
def load_dataset():
    x_train, x_test, y_train, y_test = np.load('./landmark/landmark.npy',
                                               allow_pickle=True)
    print(x_train.shape, y_train.shape)
    
    x_train = x_train.astype('float') / 256
    x_test = x_test.astype('float') / 256
    
    y_train = np_utils.to_categorical(y_train, nb_classes)   # one-hot-encoding
    y_test = np_utils.to_categorical(y_test, nb_classes)
    
    return x_train, x_test, y_train, y_test

load_dataset()
```

    (3319, 64, 64, 3) (3319,)
    




    (array([[[[0.1640625 , 0.31640625, 0.5703125 ],
              [0.1640625 , 0.31640625, 0.5703125 ],
              [0.1640625 , 0.31640625, 0.5703125 ],
              ...,
              [0.1640625 , 0.31640625, 0.578125  ],
              [0.1640625 , 0.31640625, 0.578125  ],
              [0.1640625 , 0.3125    , 0.56640625]],
     
             [[0.171875  , 0.32421875, 0.578125  ],
              [0.171875  , 0.32421875, 0.578125  ],
              [0.171875  , 0.32421875, 0.578125  ],
              ...,
              [0.171875  , 0.32421875, 0.5859375 ],
              [0.171875  , 0.32421875, 0.5859375 ],
              [0.171875  , 0.3203125 , 0.57421875]],
     
             [[0.17578125, 0.328125  , 0.58203125],
              [0.17578125, 0.328125  , 0.58203125],
              [0.17578125, 0.328125  , 0.58203125],
              ...,
              [0.17578125, 0.328125  , 0.58984375],
              [0.17578125, 0.328125  , 0.58984375],
              [0.17578125, 0.32421875, 0.578125  ]],
     
             ...,
     
             [[0.32421875, 0.4375    , 0.265625  ],
              [0.3125    , 0.4296875 , 0.234375  ],
              [0.35546875, 0.38671875, 0.1875    ],
              ...,
              [0.1328125 , 0.1171875 , 0.10546875],
              [0.17578125, 0.171875  , 0.15625   ],
              [0.15625   , 0.15234375, 0.13671875]],
     
             [[0.3359375 , 0.41015625, 0.234375  ],
              [0.33984375, 0.4140625 , 0.23828125],
              [0.34765625, 0.421875  , 0.24609375],
              ...,
              [0.05078125, 0.03125   , 0.01953125],
              [0.125     , 0.10546875, 0.09375   ],
              [0.05859375, 0.0546875 , 0.03515625]],
     
             [[0.32421875, 0.3984375 , 0.22265625],
              [0.33203125, 0.40625   , 0.23046875],
              [0.3359375 , 0.41015625, 0.234375  ],
              ...,
              [0.125     , 0.10546875, 0.09375   ],
              [0.1328125 , 0.11328125, 0.1015625 ],
              [0.234375  , 0.19921875, 0.1796875 ]]],
     
     
            [[[0.2734375 , 0.4375    , 0.71875   ],
              [0.23046875, 0.421875  , 0.6796875 ],
              [0.23046875, 0.421875  , 0.6796875 ],
              ...,
              [0.28125   , 0.3984375 , 0.6484375 ],
              [0.421875  , 0.5       , 0.70703125],
              [0.390625  , 0.45703125, 0.67578125]],
     
             [[0.265625  , 0.4140625 , 0.69140625],
              [0.26171875, 0.4453125 , 0.7109375 ],
              [0.24609375, 0.4296875 , 0.703125  ],
              ...,
              [0.296875  , 0.41796875, 0.671875  ],
              [0.3671875 , 0.46484375, 0.6875    ],
              [0.3984375 , 0.4765625 , 0.70703125]],
     
             [[0.328125  , 0.453125  , 0.69140625],
              [0.27734375, 0.43359375, 0.70703125],
              [0.26171875, 0.43359375, 0.7265625 ],
              ...,
              [0.2265625 , 0.36328125, 0.62890625],
              [0.23828125, 0.37109375, 0.62109375],
              [0.296875  , 0.40625   , 0.66015625]],
     
             ...,
     
             [[0.35546875, 0.421875  , 0.484375  ],
              [0.35546875, 0.421875  , 0.484375  ],
              [0.3828125 , 0.44921875, 0.51171875],
              ...,
              [0.15234375, 0.2421875 , 0.36328125],
              [0.12109375, 0.2109375 , 0.33203125],
              [0.1484375 , 0.23828125, 0.36328125]],
     
             [[0.35546875, 0.421875  , 0.484375  ],
              [0.34375   , 0.41015625, 0.47265625],
              [0.2109375 , 0.27734375, 0.33984375],
              ...,
              [0.078125  , 0.16796875, 0.2890625 ],
              [0.14453125, 0.234375  , 0.35546875],
              [0.15625   , 0.234375  , 0.36328125]],
     
             [[0.2734375 , 0.3359375 , 0.42578125],
              [0.171875  , 0.234375  , 0.32421875],
              [0.2109375 , 0.2734375 , 0.36328125],
              ...,
              [0.10546875, 0.1796875 , 0.30859375],
              [0.05859375, 0.12890625, 0.26953125],
              [0.015625  , 0.0859375 , 0.2421875 ]]],
     
     
            [[[0.0234375 , 0.01953125, 0.04296875],
              [0.0234375 , 0.01953125, 0.04296875],
              [0.0234375 , 0.01953125, 0.04296875],
              ...,
              [0.03125   , 0.02734375, 0.05859375],
              [0.03125   , 0.02734375, 0.05859375],
              [0.03515625, 0.03125   , 0.0546875 ]],
     
             [[0.015625  , 0.01171875, 0.03515625],
              [0.015625  , 0.01171875, 0.03515625],
              [0.015625  , 0.01171875, 0.03515625],
              ...,
              [0.02734375, 0.0234375 , 0.0546875 ],
              [0.02734375, 0.0234375 , 0.0546875 ],
              [0.03515625, 0.03125   , 0.0546875 ]],
     
             [[0.01171875, 0.0078125 , 0.03125   ],
              [0.01171875, 0.0078125 , 0.03125   ],
              [0.01171875, 0.0078125 , 0.03125   ],
              ...,
              [0.01953125, 0.015625  , 0.046875  ],
              [0.01953125, 0.015625  , 0.046875  ],
              [0.0234375 , 0.01953125, 0.04296875]],
     
             ...,
     
             [[0.12109375, 0.12109375, 0.08984375],
              [0.4609375 , 0.4609375 , 0.4296875 ],
              [0.08984375, 0.08984375, 0.05859375],
              ...,
              [0.78125   , 0.90234375, 0.97265625],
              [0.78515625, 0.921875  , 0.9296875 ],
              [0.90234375, 0.99609375, 0.99609375]],
     
             [[0.08203125, 0.0625    , 0.0390625 ],
              [0.4921875 , 0.4765625 , 0.44140625],
              [0.125     , 0.1015625 , 0.0546875 ],
              ...,
              [0.8515625 , 0.8671875 , 0.76171875],
              [0.8515625 , 0.88671875, 0.765625  ],
              [0.91796875, 0.9453125 , 0.91796875]],
     
             [[0.36328125, 0.33203125, 0.25      ],
              [0.38671875, 0.35546875, 0.265625  ],
              [0.23046875, 0.19140625, 0.0859375 ],
              ...,
              [0.95703125, 0.97265625, 0.8828125 ],
              [0.828125  , 0.8515625 , 0.75      ],
              [0.90625   , 0.953125  , 0.8984375 ]]],
     
     
            ...,
     
     
            [[[0.12890625, 0.08984375, 0.05078125],
              [0.1328125 , 0.09375   , 0.0546875 ],
              [0.13671875, 0.09765625, 0.05859375],
              ...,
              [0.12890625, 0.09375   , 0.02734375],
              [0.15234375, 0.1171875 , 0.05078125],
              [0.16015625, 0.125     , 0.05859375]],
     
             [[0.14453125, 0.10546875, 0.06640625],
              [0.1484375 , 0.109375  , 0.0703125 ],
              [0.15234375, 0.11328125, 0.07421875],
              ...,
              [0.12109375, 0.0859375 , 0.02734375],
              [0.1328125 , 0.09765625, 0.0390625 ],
              [0.140625  , 0.10546875, 0.046875  ]],
     
             [[0.15234375, 0.11328125, 0.07421875],
              [0.1484375 , 0.109375  , 0.0703125 ],
              [0.14453125, 0.10546875, 0.06640625],
              ...,
              [0.1015625 , 0.0625    , 0.015625  ],
              [0.0859375 , 0.046875  , 0.        ],
              [0.1484375 , 0.109375  , 0.0625    ]],
     
             ...,
     
             [[0.1953125 , 0.14453125, 0.0703125 ],
              [0.203125  , 0.15234375, 0.078125  ],
              [0.1796875 , 0.1171875 , 0.0546875 ],
              ...,
              [0.27734375, 0.2109375 , 0.140625  ],
              [0.234375  , 0.16796875, 0.09765625],
              [0.1875    , 0.140625  , 0.078125  ]],
     
             [[0.18359375, 0.13671875, 0.08203125],
              [0.1875    , 0.140625  , 0.0859375 ],
              [0.19140625, 0.14453125, 0.08984375],
              ...,
              [0.3671875 , 0.28515625, 0.171875  ],
              [0.3125    , 0.23046875, 0.125     ],
              [0.2265625 , 0.15625   , 0.1015625 ]],
     
             [[0.16015625, 0.1171875 , 0.09375   ],
              [0.16796875, 0.125     , 0.1015625 ],
              [0.16796875, 0.125     , 0.1015625 ],
              ...,
              [0.59375   , 0.49609375, 0.41015625],
              [0.55078125, 0.45703125, 0.36328125],
              [0.49609375, 0.4140625 , 0.34765625]]],
     
     
            [[[0.4609375 , 0.6796875 , 0.90234375],
              [0.43359375, 0.69140625, 0.9296875 ],
              [0.43359375, 0.6875    , 0.9140625 ],
              ...,
              [0.40234375, 0.64453125, 0.8828125 ],
              [0.3984375 , 0.640625  , 0.87890625],
              [0.40234375, 0.64453125, 0.8828125 ]],
     
             [[0.46484375, 0.6796875 , 0.8984375 ],
              [0.4375    , 0.6875    , 0.92578125],
              [0.43359375, 0.6875    , 0.90625   ],
              ...,
              [0.40625   , 0.6484375 , 0.88671875],
              [0.3984375 , 0.640625  , 0.87890625],
              [0.40234375, 0.64453125, 0.8828125 ]],
     
             [[0.47265625, 0.67578125, 0.8984375 ],
              [0.4375    , 0.69140625, 0.91796875],
              [0.44140625, 0.6875    , 0.8984375 ],
              ...,
              [0.41015625, 0.65234375, 0.890625  ],
              [0.40625   , 0.6484375 , 0.88671875],
              [0.40234375, 0.64453125, 0.8828125 ]],
     
             ...,
     
             [[0.3125    , 0.3671875 , 0.13671875],
              [0.37109375, 0.37890625, 0.234375  ],
              [0.21484375, 0.2265625 , 0.15234375],
              ...,
              [0.3359375 , 0.29296875, 0.21484375],
              [0.30078125, 0.26953125, 0.1875    ],
              [0.29296875, 0.28515625, 0.203125  ]],
     
             [[0.23828125, 0.26953125, 0.1171875 ],
              [0.1953125 , 0.19140625, 0.07421875],
              [0.26171875, 0.26953125, 0.1875    ],
              ...,
              [0.3828125 , 0.359375  , 0.1640625 ],
              [0.33984375, 0.328125  , 0.12890625],
              [0.34765625, 0.359375  , 0.15234375]],
     
             [[0.23828125, 0.26171875, 0.16015625],
              [0.22265625, 0.21484375, 0.125     ],
              [0.2421875 , 0.25      , 0.1640625 ],
              ...,
              [0.42578125, 0.40625   , 0.1796875 ],
              [0.51171875, 0.50390625, 0.2734375 ],
              [0.34375   , 0.36328125, 0.11328125]]],
     
     
            [[[0.6015625 , 0.53125   , 0.4453125 ],
              [0.5859375 , 0.484375  , 0.35546875],
              [0.5078125 , 0.3671875 , 0.2421875 ],
              ...,
              [0.51171875, 0.51171875, 0.46484375],
              [0.3515625 , 0.39453125, 0.36328125],
              [0.390625  , 0.42578125, 0.453125  ]],
     
             [[0.51171875, 0.44140625, 0.35546875],
              [0.57421875, 0.4765625 , 0.35546875],
              [0.52734375, 0.39453125, 0.28515625],
              ...,
              [0.234375  , 0.23828125, 0.17578125],
              [0.8359375 , 0.87890625, 0.84765625],
              [0.23828125, 0.2734375 , 0.30078125]],
     
             [[0.53125   , 0.4609375 , 0.3828125 ],
              [0.4140625 , 0.33203125, 0.2265625 ],
              [0.35546875, 0.2578125 , 0.1796875 ],
              ...,
              [0.75      , 0.7578125 , 0.67578125],
              [0.9375    , 0.9765625 , 0.9453125 ],
              [0.33984375, 0.3671875 , 0.3984375 ]],
     
             ...,
     
             [[0.32421875, 0.41015625, 0.5546875 ],
              [0.17578125, 0.26953125, 0.40234375],
              [0.11328125, 0.22265625, 0.37890625],
              ...,
              [0.8828125 , 0.52734375, 0.2421875 ],
              [0.8125    , 0.4921875 , 0.265625  ],
              [0.8984375 , 0.57421875, 0.27734375]],
     
             [[0.1796875 , 0.25390625, 0.41015625],
              [0.3828125 , 0.48046875, 0.59765625],
              [0.078125  , 0.17578125, 0.33203125],
              ...,
              [0.8515625 , 0.5390625 , 0.26953125],
              [0.7734375 , 0.45703125, 0.2421875 ],
              [0.84765625, 0.52734375, 0.2421875 ]],
     
             [[0.125     , 0.19921875, 0.35546875],
              [0.18359375, 0.27734375, 0.38671875],
              [0.3828125 , 0.48046875, 0.63671875],
              ...,
              [0.76171875, 0.46875   , 0.21484375],
              [0.7421875 , 0.4296875 , 0.22265625],
              [0.78125   , 0.46875   , 0.19140625]]]]),
     array([[[[0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              ...,
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ]],
     
             [[0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              ...,
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ]],
     
             [[0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              ...,
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ]],
     
             ...,
     
             [[0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              ...,
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ]],
     
             [[0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              ...,
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ]],
     
             [[0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              ...,
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ],
              [0.        , 0.        , 0.        ]]],
     
     
            [[[0.01953125, 0.01953125, 0.01171875],
              [0.0234375 , 0.0234375 , 0.015625  ],
              [0.03125   , 0.03125   , 0.0234375 ],
              ...,
              [0.0234375 , 0.03125   , 0.01953125],
              [0.0234375 , 0.03125   , 0.01953125],
              [0.0234375 , 0.03125   , 0.02734375]],
     
             [[0.0234375 , 0.0234375 , 0.015625  ],
              [0.03125   , 0.03125   , 0.0234375 ],
              [0.03515625, 0.03515625, 0.02734375],
              ...,
              [0.0234375 , 0.03125   , 0.01953125],
              [0.0234375 , 0.03125   , 0.01953125],
              [0.0234375 , 0.03125   , 0.02734375]],
     
             [[0.02734375, 0.02734375, 0.01953125],
              [0.03515625, 0.03515625, 0.02734375],
              [0.0390625 , 0.0390625 , 0.03125   ],
              ...,
              [0.0234375 , 0.03125   , 0.01953125],
              [0.0234375 , 0.03125   , 0.01953125],
              [0.0234375 , 0.03125   , 0.02734375]],
     
             ...,
     
             [[0.03515625, 0.03515625, 0.03515625],
              [0.04296875, 0.04296875, 0.04296875],
              [0.0390625 , 0.0390625 , 0.0390625 ],
              ...,
              [0.02734375, 0.03125   , 0.01171875],
              [0.0234375 , 0.03125   , 0.01171875],
              [0.02734375, 0.02734375, 0.01953125]],
     
             [[0.03515625, 0.03515625, 0.03515625],
              [0.04296875, 0.04296875, 0.04296875],
              [0.0390625 , 0.0390625 , 0.0390625 ],
              ...,
              [0.015625  , 0.0390625 , 0.0234375 ],
              [0.02734375, 0.03515625, 0.0234375 ],
              [0.02734375, 0.02734375, 0.01953125]],
     
             [[0.03125   , 0.03125   , 0.0234375 ],
              [0.0390625 , 0.0390625 , 0.03125   ],
              [0.03515625, 0.03515625, 0.02734375],
              ...,
              [0.03125   , 0.03125   , 0.0234375 ],
              [0.03125   , 0.03125   , 0.0234375 ],
              [0.02734375, 0.03515625, 0.0234375 ]]],
     
     
            [[[0.83984375, 0.87109375, 0.8828125 ],
              [0.82421875, 0.8671875 , 0.9765625 ],
              [0.8046875 , 0.87109375, 0.94921875],
              ...,
              [0.99609375, 0.99609375, 0.99609375],
              [0.99609375, 0.99609375, 0.99609375],
              [0.99609375, 0.99609375, 0.99609375]],
     
             [[0.828125  , 0.8828125 , 0.91796875],
              [0.73046875, 0.8046875 , 0.93359375],
              [0.73828125, 0.83203125, 0.93359375],
              ...,
              [0.99609375, 0.99609375, 0.99609375],
              [0.99609375, 0.99609375, 0.99609375],
              [0.99609375, 0.99609375, 0.99609375]],
     
             [[0.8203125 , 0.890625  , 0.9375    ],
              [0.75      , 0.8359375 , 0.98046875],
              [0.74609375, 0.8515625 , 0.96484375],
              ...,
              [0.99609375, 0.99609375, 0.99609375],
              [0.99609375, 0.99609375, 0.99609375],
              [0.99609375, 0.99609375, 0.99609375]],
     
             ...,
     
             [[0.48046875, 0.5       , 0.47265625],
              [0.17578125, 0.20703125, 0.15625   ],
              [0.16015625, 0.203125  , 0.13671875],
              ...,
              [0.4140625 , 0.421875  , 0.33984375],
              [0.47265625, 0.48046875, 0.39453125],
              [0.60546875, 0.61328125, 0.51953125]],
     
             [[0.48046875, 0.50390625, 0.46484375],
              [0.17578125, 0.20703125, 0.1484375 ],
              [0.17578125, 0.22265625, 0.14453125],
              ...,
              [0.3359375 , 0.33984375, 0.27734375],
              [0.3125    , 0.3203125 , 0.23828125],
              [0.55078125, 0.55859375, 0.46484375]],
     
             [[0.5859375 , 0.609375  , 0.5625    ],
              [0.42578125, 0.45703125, 0.3984375 ],
              [0.5078125 , 0.5546875 , 0.4765625 ],
              ...,
              [0.87109375, 0.875     , 0.8203125 ],
              [0.53125   , 0.5390625 , 0.45703125],
              [0.63671875, 0.64453125, 0.55859375]]],
     
     
            ...,
     
     
            [[[0.34375   , 0.44140625, 0.6640625 ],
              [0.34375   , 0.44140625, 0.6640625 ],
              [0.34375   , 0.44140625, 0.6640625 ],
              ...,
              [0.21875   , 0.30859375, 0.57421875],
              [0.21875   , 0.30859375, 0.57421875],
              [0.21875   , 0.30859375, 0.57421875]],
     
             [[0.34375   , 0.44140625, 0.6640625 ],
              [0.34375   , 0.44140625, 0.6640625 ],
              [0.34375   , 0.44140625, 0.6640625 ],
              ...,
              [0.22265625, 0.3125    , 0.578125  ],
              [0.22265625, 0.3125    , 0.578125  ],
              [0.22265625, 0.3125    , 0.578125  ]],
     
             [[0.34375   , 0.44140625, 0.6640625 ],
              [0.34375   , 0.44140625, 0.6640625 ],
              [0.34375   , 0.44140625, 0.6640625 ],
              ...,
              [0.2265625 , 0.31640625, 0.58203125],
              [0.2265625 , 0.31640625, 0.58203125],
              [0.2265625 , 0.31640625, 0.58203125]],
     
             ...,
     
             [[0.38671875, 0.34765625, 0.30078125],
              [0.2734375 , 0.23046875, 0.21484375],
              [0.3046875 , 0.26171875, 0.25390625],
              ...,
              [0.56640625, 0.5078125 , 0.35546875],
              [0.60546875, 0.54296875, 0.33984375],
              [0.62890625, 0.57421875, 0.28125   ]],
     
             [[0.28125   , 0.24609375, 0.1796875 ],
              [0.375     , 0.33203125, 0.31640625],
              [0.3125    , 0.26953125, 0.24609375],
              ...,
              [0.6171875 , 0.55078125, 0.44140625],
              [0.51171875, 0.453125  , 0.29296875],
              [0.6640625 , 0.6015625 , 0.3671875 ]],
     
             [[0.359375  , 0.328125  , 0.25390625],
              [0.3515625 , 0.30859375, 0.28515625],
              [0.27734375, 0.23828125, 0.19921875],
              ...,
              [0.59765625, 0.54296875, 0.40625   ],
              [0.54296875, 0.48828125, 0.3046875 ],
              [0.63671875, 0.58203125, 0.328125  ]]],
     
     
            [[[0.66796875, 0.75390625, 0.84375   ],
              [0.67578125, 0.76171875, 0.8515625 ],
              [0.6796875 , 0.765625  , 0.85546875],
              ...,
              [0.65234375, 0.734375  , 0.80859375],
              [0.65234375, 0.734375  , 0.80859375],
              [0.65234375, 0.734375  , 0.80859375]],
     
             [[0.671875  , 0.7578125 , 0.84765625],
              [0.6796875 , 0.765625  , 0.85546875],
              [0.6796875 , 0.765625  , 0.85546875],
              ...,
              [0.66015625, 0.73046875, 0.80859375],
              [0.66015625, 0.73046875, 0.80859375],
              [0.66015625, 0.73046875, 0.80859375]],
     
             [[0.6796875 , 0.76171875, 0.84375   ],
              [0.6875    , 0.76953125, 0.8515625 ],
              [0.68359375, 0.765625  , 0.84765625],
              ...,
              [0.6640625 , 0.73046875, 0.80859375],
              [0.6640625 , 0.73046875, 0.80859375],
              [0.6640625 , 0.73046875, 0.80859375]],
     
             ...,
     
             [[0.43359375, 0.33984375, 0.19921875],
              [0.734375  , 0.671875  , 0.53125   ],
              [0.7890625 , 0.76171875, 0.59765625],
              ...,
              [0.54296875, 0.375     , 0.33984375],
              [0.42578125, 0.41015625, 0.46875   ],
              [0.72265625, 0.62109375, 0.53125   ]],
     
             [[0.80078125, 0.70703125, 0.59765625],
              [0.63671875, 0.5703125 , 0.453125  ],
              [0.81640625, 0.78515625, 0.640625  ],
              ...,
              [0.3671875 , 0.25      , 0.2109375 ],
              [0.63671875, 0.59765625, 0.62890625],
              [0.56640625, 0.47265625, 0.37109375]],
     
             [[0.78515625, 0.69921875, 0.6171875 ],
              [0.87109375, 0.80859375, 0.7109375 ],
              [0.8359375 , 0.80078125, 0.6796875 ],
              ...,
              [0.71875   , 0.65234375, 0.62109375],
              [0.50390625, 0.44921875, 0.4375    ],
              [0.890625  , 0.80078125, 0.6796875 ]]],
     
     
            [[[0.71875   , 0.7578125 , 0.7265625 ],
              [0.71875   , 0.7578125 , 0.7265625 ],
              [0.7421875 , 0.78125   , 0.75      ],
              ...,
              [0.68359375, 0.74609375, 0.80859375],
              [0.671875  , 0.74609375, 0.8125    ],
              [0.62890625, 0.71875   , 0.7890625 ]],
     
             [[0.73046875, 0.76953125, 0.73828125],
              [0.73046875, 0.76953125, 0.73828125],
              [0.7109375 , 0.75      , 0.71875   ],
              ...,
              [0.65234375, 0.7265625 , 0.79296875],
              [0.63671875, 0.71875   , 0.79296875],
              [0.6015625 , 0.70703125, 0.7890625 ]],
     
             [[0.734375  , 0.7734375 , 0.7421875 ],
              [0.734375  , 0.7734375 , 0.7421875 ],
              [0.6953125 , 0.734375  , 0.703125  ],
              ...,
              [0.62890625, 0.7109375 , 0.79296875],
              [0.609375  , 0.70703125, 0.79296875],
              [0.58203125, 0.703125  , 0.78515625]],
     
             ...,
     
             [[0.3671875 , 0.359375  , 0.26171875],
              [0.4375    , 0.4296875 , 0.33203125],
              [0.41015625, 0.40234375, 0.3046875 ],
              ...,
              [0.328125  , 0.31640625, 0.25      ],
              [0.2890625 , 0.27734375, 0.2109375 ],
              [0.35546875, 0.34375   , 0.27734375]],
     
             [[0.34375   , 0.3359375 , 0.25390625],
              [0.31640625, 0.30859375, 0.2265625 ],
              [0.3671875 , 0.359375  , 0.27734375],
              ...,
              [0.453125  , 0.44140625, 0.375     ],
              [0.3671875 , 0.35546875, 0.2890625 ],
              [0.375     , 0.36328125, 0.296875  ]],
     
             [[0.3203125 , 0.30859375, 0.25      ],
              [0.421875  , 0.41015625, 0.3515625 ],
              [0.36328125, 0.3515625 , 0.29296875],
              ...,
              [0.25      , 0.23828125, 0.171875  ],
              [0.33203125, 0.3203125 , 0.25390625],
              [0.30078125, 0.2890625 , 0.22265625]]]]),
     array([[0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 1., 0., 0.],
            ...,
            [0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),
     array([[0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 0., 0., 0.],
            ...,
            [0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 0., 1., 0.]], dtype=float32))




```python
# 모델 구성 함수 생성(Convolution2D, Activation, MaxPooling, Dropout, etc.) 

def build_model(in_shape):
    model = Sequential()
    
    model.add(Convolution2D(32,3,3, border_mode='Same', input_shape=in_shape))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(0.25))
    
    model.add(Convolution2D(64,3,3, border_mode='Same'))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(0.25))
    
    model.add(Flatten())
    model.add(Dense(512))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(nb_classes))
    model.add(Activation('softmax'))
    
    model.compile(loss='categorical_crossentropy',
                  optimizer='rmsprop',
                  metrics=['accuracy'])
    
    return model
```


```python
# 모델 학습 함수 생성(batch_size, epochs) 

def model_train(x, y):
    print(x.shape[1:])
    model = build_model(x.shape[1:])
    model.fit(x, y, batch_size=32, epochs=30)
    
    return model

```


```python
# 모델 평가 함수 생성(loss & accuracy)

def model_eval(model, x, y):
    score = model.evaluate(x, y)
    print('loss = ', score[0])
    print('accuracy = ', score[1])
```


```python
# 모델 생성, 학습, 평가

# 데이터 불러오기 
x_train, x_test, y_train, y_test = load_dataset()

# 모델 학습
model = model_train(x_train, y_train)

# 학습이 완료된 모델을 저장
model.save('./landmark/landmark_model.h5')
```

    (3319, 64, 64, 3) (3319,)
    (64, 64, 3)
    WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
    Instructions for updating:
    If using Keras pass *_constraint arguments to layers.
    WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.
    
    

    C:\ProgramData\Anaconda3\lib\site-packages\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., padding="Same")`
      
    C:\ProgramData\Anaconda3\lib\site-packages\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding="Same")`
      # This is added back by InteractiveShellApp.init_path()
    

    WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.
    
    Epoch 1/30
    3319/3319 [==============================] - 33s 10ms/step - loss: 2.6894 - accuracy: 0.1874
    Epoch 2/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 1.9199 - accuracy: 0.4071
    Epoch 3/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 1.5372 - accuracy: 0.5264
    Epoch 4/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 1.3181 - accuracy: 0.6038
    Epoch 5/30
    3319/3319 [==============================] - 31s 9ms/step - loss: 1.0761 - accuracy: 0.6728
    Epoch 6/30
    3319/3319 [==============================] - 31s 9ms/step - loss: 0.9151 - accuracy: 0.7249
    Epoch 7/30
    3319/3319 [==============================] - 33s 10ms/step - loss: 0.7389 - accuracy: 0.7776
    Epoch 8/30
    3319/3319 [==============================] - 33s 10ms/step - loss: 0.6122 - accuracy: 0.8081
    Epoch 9/30
    3319/3319 [==============================] - 33s 10ms/step - loss: 0.5306 - accuracy: 0.8313
    Epoch 10/30
    3319/3319 [==============================] - 34s 10ms/step - loss: 0.4231 - accuracy: 0.8668
    Epoch 11/30
    3319/3319 [==============================] - 35s 11ms/step - loss: 0.3562 - accuracy: 0.8897
    Epoch 12/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.3020 - accuracy: 0.9033
    Epoch 13/30
    3319/3319 [==============================] - 31s 9ms/step - loss: 0.2526 - accuracy: 0.9196
    Epoch 14/30
    3319/3319 [==============================] - 31s 9ms/step - loss: 0.2175 - accuracy: 0.9307
    Epoch 15/30
    3319/3319 [==============================] - 30s 9ms/step - loss: 0.2008 - accuracy: 0.9373
    Epoch 16/30
    3319/3319 [==============================] - 33s 10ms/step - loss: 0.1530 - accuracy: 0.9509
    Epoch 17/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.1503 - accuracy: 0.9524
    Epoch 18/30
    3319/3319 [==============================] - 33s 10ms/step - loss: 0.1338 - accuracy: 0.9584
    Epoch 19/30
    3319/3319 [==============================] - 33s 10ms/step - loss: 0.1115 - accuracy: 0.9632
    Epoch 20/30
    3319/3319 [==============================] - 33s 10ms/step - loss: 0.1149 - accuracy: 0.9638
    Epoch 21/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.1206 - accuracy: 0.9629
    Epoch 22/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.0860 - accuracy: 0.9726
    Epoch 23/30
    3319/3319 [==============================] - 31s 9ms/step - loss: 0.0945 - accuracy: 0.9684
    Epoch 24/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.0876 - accuracy: 0.9726
    Epoch 25/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.0954 - accuracy: 0.9693
    Epoch 26/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.0911 - accuracy: 0.9732
    Epoch 27/30
    3319/3319 [==============================] - 31s 9ms/step - loss: 0.0675 - accuracy: 0.9780
    Epoch 28/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.0926 - accuracy: 0.9720
    Epoch 29/30
    3319/3319 [==============================] - 31s 9ms/step - loss: 0.0727 - accuracy: 0.9786
    Epoch 30/30
    3319/3319 [==============================] - 32s 10ms/step - loss: 0.0931 - accuracy: 0.9741
    

## III. Model run


```python
# 테스트 이미지 목록
image_files = ["E:\\Eric_Github\\Image_project\\landmark_test\\burj_test\\burj-khalifa-4922311__340.jpg",
               "E:\\Eric_Github\\Image_project\\landmark_test\\colo_test\\colosseum-601763__340.jpg",
               "E:\\Eric_Github\\Image_project\\landmark_test\\Eiffel_test\\eiffel-tower-2063907__340.jpg",
               "E:\\Eric_Github\\Image_project\\landmark_test\\moai_test\\chile-1740813__340.jpg",
               "E:\\Eric_Github\\Image_project\\landmark_test\\Pisa_test\\tower-of-pisa-4426291__340.jpg",
               "E:\\Eric_Github\\Image_project\\landmark_test\\Santiago Bernabéu\\Santiago Bernabéu04.jpg",
               "E:\\Eric_Github\\Image_project\\landmark_test\\Wànlĭ Chángchéng\\the-great-wall-606451_1920.jpg",
               ]

```


```python
from keras.models import load_model
```


```python
# 예측할 새로운 이미지 불러오기

X = []
files = []

for fname in image_files:
    img = Image.open(fname)   # 파일 불러오기
    img = img.convert('RGB')
    img = img.resize((image_size, image_size))
    in_data = np.asarray(img)
    in_data = in_data.astype('float')/256
    X.append(in_data)
    files.append(fname)
    
X = np.array(X)
print(X.shape)
```

    (7, 64, 64, 3)
    


```python
# 테스트 이미지를 활용한 예측 모델 실행

model = load_model('./landmark/landmark_model.h5')

pre = model.predict(X)

# 결과 출력
for i, p in enumerate(pre):
    y = p.argmax()
    print('입력 : ', files[i])
    print('예측 : ', y)
```

    입력 :  E:\Eric_Github\Image_project\landmark_test\burj_test\burj-khalifa-4922311__340.jpg
    예측 :  14
    입력 :  E:\Eric_Github\Image_project\landmark_test\colo_test\colosseum-601763__340.jpg
    예측 :  11
    입력 :  E:\Eric_Github\Image_project\landmark_test\Eiffel_test\eiffel-tower-2063907__340.jpg
    예측 :  0
    입력 :  E:\Eric_Github\Image_project\landmark_test\moai_test\chile-1740813__340.jpg
    예측 :  12
    입력 :  E:\Eric_Github\Image_project\landmark_test\Pisa_test\tower-of-pisa-4426291__340.jpg
    예측 :  10
    입력 :  E:\Eric_Github\Image_project\landmark_test\Santiago Bernabéu\Santiago Bernabéu04.jpg
    예측 :  12
    입력 :  E:\Eric_Github\Image_project\landmark_test\Wànlĭ Chángchéng\the-great-wall-606451_1920.jpg
    예측 :  0
    


```python
# 결과 출력 
model_eval(model, x_test, y_test)
```

    1107/1107 [==============================] - 2s 1ms/step
    loss =  2.1945936796141834
    accuracy =  0.6711834073066711
    
